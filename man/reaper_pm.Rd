% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/python_ssff.R
\name{reaper_pm}
\alias{reaper_pm}
\title{Extract pitch marks using the REAPER algoritm}
\usage{
reaper_pm(
  listOfFiles,
  beginTime = 0,
  endTime = 0,
  windowShift = 10,
  minF = 40,
  maxF = 500,
  unvoiced_cost = 0.9,
  high.pass = TRUE,
  hilbert.transform = FALSE,
  explicitExt = "rpm",
  outputDirectory = NULL,
  toFile = TRUE,
  conda.env = "pysuperassp"
)
}
\arguments{
\item{listOfFiles}{A vector of file paths to wav files.}

\item{beginTime}{The start time of the section of the sound file that should be processed.}

\item{endTime}{The end time of the section of the sound file that should be processed.}

\item{windowShift}{The measurement interval (frame duration), in seconds.}

\item{minF}{Candidate f0 frequencies below this frequency will not be considered.}

\item{maxF}{Candidates above this frequency will be ignored.}

\item{unvoiced_cost}{Set the cost for unvoiced segments. Default is 0.9, the higher the value the more f0 estimates in noise.}

\item{high.pass}{Perform high-pass filtering to remove DC and low-frequency noise?}

\item{hilbert.transform}{Remove phase distortion using Hilbert transform?}

\item{explicitExt}{the file extension that should be used.}

\item{outputDirectory}{set an explicit directory for where the signal file will be written. If not defined, the file will be written to the same directory as the sound file.}

\item{toFile}{write the output to a file? The file will be written in  \code{outputDirectory}, if defined, or in the same directory as the soundfile.}

\item{conda.env}{The name of the conda environment in which Python and its required packages are stored. Please make sure that you know what you are doing if you change this.}
}
\value{
An SSFF track object containing two tracks (f0 and corr) that are
either returned (toFile == FALSE) or stored on disk.
}
\description{
Robust Epoch And Pitch EstimatoR (REAPER) algorithm
\insertCite{talkin2019reaper}{superassp} uses an EpochTracker class to
simultaneously estimate the location of voiced-speech "epochs" or glottal
closure instants (GCI), voicing state (voiced or unvoiced) and fundamental
frequency (F0 or "pitch"). This function returns the voicing state of each
windowed \code{windowShift} (ms) portion of the signal.
}
\details{
DC bias and low-frequency noise are removed by high-pass filtering, and the
signal is converted to floating point. If the input is known to have phase
distortion that is impacting tracker performance, a Hilbert transform,
optionally done at this point, may improve performance.

The function uses the python library \code{pyreaper} combined with the R
package \link{reticulate} to compute the tracks, and the user therefore has to
make sure that \code{pyreaper} and python is available on the machine. It is
recommended to set up an anaconda ("conda") environment for the superassp
library, like this:

\if{html}{\out{<div class="sourceCode">}}\preformatted{conda create conda create --prefix -n pysuperassp python=3.8 
conda activate pysuperassp 
pip install librosa
pip install pyreaper 
#Not used by
this function but by other functions in this package 
pip install pysptk 
}\if{html}{\out{</div>}}
}
\references{
\insertAllCited{}
}
