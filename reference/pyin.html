<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="description" content="The probabilistic YIN algorithm
(Mauch and Dixon 2014)
 is an
extension of YIN (Cheveigné and Kawahara 2002)
 that considers multiple pitch
candidates in a hidden Markov model that is Viterbi-decoded to deduce the
final pitch estimate. The function also returns a track encoding whether the
track was considered voiced or not, and a track containing the probability of
voicing in the analysis frame."><title>Estimate pitch using the probabilistic YIN algorithm — pyin • superassp</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Estimate pitch using the probabilistic YIN algorithm — pyin"><meta property="og:description" content="The probabilistic YIN algorithm
(Mauch and Dixon 2014)
 is an
extension of YIN (Cheveigné and Kawahara 2002)
 that considers multiple pitch
candidates in a hidden Markov model that is Viterbi-decoded to deduce the
final pitch estimate. The function also returns a track encoding whether the
track was considered voiced or not, and a track containing the probability of
voicing in the analysis frame."><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">superassp</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.1</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
      </ul><form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off"></form>

      <ul class="navbar-nav"></ul></div>

    
  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Estimate pitch using the probabilistic YIN algorithm</h1>
      
      <div class="d-none name"><code>pyin.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>The probabilistic YIN algorithm
(Mauch and Dixon 2014)
 is an
extension of <a href="yin.html">YIN</a> (Cheveigné and Kawahara 2002)
 that considers multiple pitch
candidates in a hidden Markov model that is Viterbi-decoded to deduce the
final pitch estimate. The function also returns a track encoding whether the
track was considered voiced or not, and a track containing the probability of
voicing in the analysis frame.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">pyin</span><span class="op">(</span></span>
<span>  <span class="va">listOfFiles</span>,</span>
<span>  beginTime <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  endTime <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  windowShift <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  windowSize <span class="op">=</span> <span class="fl">30</span>,</span>
<span>  minF <span class="op">=</span> <span class="fl">70</span>,</span>
<span>  maxF <span class="op">=</span> <span class="fl">200</span>,</span>
<span>  max_transition_rate <span class="op">=</span> <span class="fl">35.92</span>,</span>
<span>  beta_parameters <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">18</span><span class="op">)</span>,</span>
<span>  center <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  boltzmann_parameter <span class="op">=</span> <span class="fl">2</span>,</span>
<span>  resolution <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span>  thresholds <span class="op">=</span> <span class="fl">100</span>,</span>
<span>  switch_probability <span class="op">=</span> <span class="fl">0.01</span>,</span>
<span>  no_trough_probability <span class="op">=</span> <span class="fl">0.01</span>,</span>
<span>  pad_mode <span class="op">=</span> <span class="st">"constant"</span>,</span>
<span>  explicitExt <span class="op">=</span> <span class="st">"pyp"</span>,</span>
<span>  outputDirectory <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  toFile <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>
    <dl><dt>listOfFiles</dt>
<dd><p>A vector of file paths to wav files.</p></dd>


<dt>beginTime</dt>
<dd><p>The start time of the section of the sound file that should be processed.</p></dd>


<dt>endTime</dt>
<dd><p>The end time of the section of the sound file that should be processed.</p></dd>


<dt>windowShift</dt>
<dd><p>The measurement interval (frame duration), in seconds.</p></dd>


<dt>minF</dt>
<dd><p>Candidate f0 frequencies below this frequency will not be considered.</p></dd>


<dt>maxF</dt>
<dd><p>Candidates above this frequency will be ignored.</p></dd>


<dt>max_transition_rate</dt>
<dd><p>The maximum pitch transition rate in octaves per second.</p></dd>


<dt>beta_parameters</dt>
<dd><p>The shape parameters for the beta distribution prior over thresholds.</p></dd>


<dt>center</dt>
<dd><p>Should analysis windows be centered around the time of the
window (<code>TRUE</code>, the default) or should the window be considered to have
started at the indicated time point (<code>FALSE</code>).</p></dd>


<dt>boltzmann_parameter</dt>
<dd><p>The shape parameter for the Boltzmann distribution prior over troughs. Larger values will assign more mass to smaller periods.</p></dd>


<dt>resolution</dt>
<dd><p>The resolution of the pitch bins. 0.01 corresponds to cents.</p></dd>


<dt>thresholds</dt>
<dd><p>The number of thresholds for peak estimation.</p></dd>


<dt>switch_probability</dt>
<dd><p>The probability of switching from voiced to unvoiced or vice versa.</p></dd>


<dt>no_trough_probability</dt>
<dd><p>The maximum probability to add to global minimum if no trough is below threshold.</p></dd>


<dt>pad_mode</dt>
<dd><p>The mode in which padding occurs. Ignored if <code>center</code> is not
<code>TRUE</code>. Padding occurs in the python library librosa, and the user should
therefore consult the manual of the NumPy library function
<a href="https://numpy.org/doc/stable/reference/generated/numpy.pad.html#numpy-pad" class="external-link">numpy.pad</a> for other options.</p></dd>


<dt>explicitExt</dt>
<dd><p>the file extension that should be used.</p></dd>


<dt>outputDirectory</dt>
<dd><p>set an explicit directory for where the signal file will be written. If not defined, the file will be written to the same directory as the sound file.</p></dd>


<dt>toFile</dt>
<dd><p>write the output to a file? The file will be written in  <code>outputDirectory</code>, if defined, or in the same directory as the soundfile.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    

<p>An SSFF track object containing two tracks (f0 and pitch) that are either returned (toFile == FALSE) or stored on disk.</p>
    </div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>This function calls the librosa (McFee et al. 2022)
 Python library to load the audio data an
make pitch related estimates.</p>
    </div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>
    <p>Cheveigné Ad, Kawahara H (2002).
“YIN, a fundamental frequency estimator for speech and music.”
<em>The Journal of the Acoustical Society of America</em>, <b>111</b>(4), 1917--1930.
ISSN 0001-4966, <a href="https://doi.org/10.1121/1.1458024" class="external-link">doi:10.1121/1.1458024</a>
, <a href="http://www.ncbi.nlm.nih.gov/pubmed/12002874" class="external-link">http://www.ncbi.nlm.nih.gov/pubmed/12002874</a>.<br><br> Mauch M, Dixon S (2014).
“PYIN: A Fundamental Frequency Estimator using Probabilistic Threshold Distributions.”
<em>2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 659--663.
<a href="https://doi.org/10.1109/icassp.2014.6853678" class="external-link">doi:10.1109/icassp.2014.6853678</a>
.<br><br> McFee B, Metsai A, McVicar M, Balke S, Thomé C, Raffel C, Zalkow F, Malek A, Dana, Lee K, Nieto O, Ellis D, Mason J, Battenberg E, Seyfarth S, Yamamoto R, viktorandreevichmorozov, Choi K, Moore J, Bittner R, Hidaka S, Wei Z, nullmightybofo, Weiss A, Hereñú D, Stöter F, Friesch P, Vollrath M, Kim T, Thassilo (2022).
“librosa/librosa: 0.9.1.”
<a href="https://doi.org/10.5281/zenodo.6097378" class="external-link">doi:10.5281/zenodo.6097378</a>
.</p>
    </div>

  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p></p><p>Developed by Fredrik Karlsson.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer></div>

  

  

  </body></html>

